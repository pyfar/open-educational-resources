{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: VBAP and HRTF\n",
    "*Sebastian J. Schlecht (1), Nils Meyer-Kahlen (2)*<br>\n",
    "\n",
    "Notebook: *Cristóbal Andrade (1)*<br>\n",
    "\n",
    "*(1) Friedrich-Alexander-Universität Erlangen-Nürnberg*<br>\n",
    "*(2) Aalto University*<br>\n",
    "\n",
    "*Contact: sebastian.schlecht@fau.de, cristobal.andrade@fau.de*\n",
    "\n",
    "The rendered scene in this assignment is rotating music band. You will learn how to implement VBAP and apply a set of HRTFs to binauralize the directional sound experience.\n",
    "\n",
    "**Duration:** 12 Hours\n",
    "\n",
    "**References**   \n",
    "Pulkki, V. (1997). Virtual Sound Source Positioning Using Vector Base Amplitude Panning. JAES, 144(5)\n",
    "\n",
    "\n",
    "**Dependencies**  \n",
    "`matplotlib numpy pooch pyfar scipy sofar soundfile ipywidgets ipymp`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sfile\n",
    "import numpy as np\n",
    "import pooch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Config import Config\n",
    "from Binaural_DSP import BinauralDSP, sph2cart\n",
    "from VBAP_DSP import VBAP_DSP, sph2cart_vec\n",
    "from Scene import rotating_band_scene\n",
    "from cart2sph_vec import cart2sph_vec\n",
    "\n",
    "%matplotlib inline\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this as it is: This is the URL from which the data will be downloaded\n",
    "\n",
    "url_py = 'https://github.com/pyfar/open-educational-resources/raw/main/courses/Virtual_Acoustics_Lab_FAU/Assignment2'\n",
    "url_large_files = 'https://github.com/pyfar/files/raw/main/education/VAL_FAU'\n",
    "url_hrtfs = 'https://github.com/pyfar/files/raw/main/education/VAR_TUB'\n",
    "\n",
    "# Get current working directory (where the notebook was started)\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Create a Pooch object using that directory\n",
    "my_pooch_py = pooch.create(\n",
    "    path=notebook_dir,\n",
    "    base_url=url_py,\n",
    "    registry={\n",
    "        \"Scene.py\" : None,\n",
    "        \"Binaural_DSP.py\" : None,\n",
    "        \"DSP.py\" : None,\n",
    "        \"cart2sph_vec.py\" : None,\n",
    "        \"VBAP_DSP.py\" : None,\n",
    "        \"hrirsDiffuseFieldEQ.py\" : None,\n",
    "        \"BlockConvolver_DSP.py\" : None,\n",
    "        \"Config.py\" : None,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "my_pooch_large_files = pooch.create(\n",
    "    path=notebook_dir,\n",
    "    base_url=url_large_files, \n",
    "    registry={\n",
    "        \"rotatingBand.wav\" : None,\n",
    "        \"band_combined_snip.wav\" : None,\n",
    "    }\n",
    ")\n",
    "\n",
    "my_pooch_hrtfs = pooch.create(\n",
    "    path=notebook_dir,\n",
    "    base_url=url_hrtfs,\n",
    "    registry={\n",
    "        \"FABIAN_HRIR_measured_HATO_0.sofa\" : None\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Download all files\n",
    "for fname in my_pooch_py.registry:\n",
    "    fpath = my_pooch_py.fetch(fname)\n",
    "    print(f\"Downloaded: {fpath}\")\n",
    "    \n",
    "for fname in my_pooch_large_files.registry:\n",
    "    fpath = my_pooch_large_files.fetch(fname)\n",
    "    print(f\"Downloaded: {fpath}\")\n",
    "    \n",
    "for fname in my_pooch_hrtfs.registry:\n",
    "    fpath = my_pooch_hrtfs.fetch(fname)\n",
    "    print(f\"Downloaded: {fpath}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Upon completing this assignment, you will be able to binauralize a multichannel recording, resulting in the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderedSignal, fs = sfile.read('rotatingBand.wav')  \n",
    "\n",
    "display(Audio(renderedSignal.T, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BINAURALIZE with HRTFs\n",
    "For that, we first need a set of HRTFs. We provide you with a function that loads a SOFA (Spatially Oriented Format for Acoustics) file from the internet. You can see this set was measured on a very dense grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize binauralizer with empty source\n",
    "binauralizer = BinauralDSP(config, None)\n",
    "\n",
    "# Create 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(binauralizer.hrir_positions[:, 0], \n",
    "           binauralizer.hrir_positions[:, 1], \n",
    "           binauralizer.hrir_positions[:, 2])\n",
    "        \n",
    "ax.view_init(elev=20, azim=30)\n",
    "ax.set_title(\"HRIR Measurement Grid\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "ax.set_box_aspect([1, 1, 1])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 TASK: Plot HRIR\n",
    "As an example, lets plot the HRIRs of a source at [90 0] deg (left). For that we first have to choose the appropriate set of HRIRs. For such a dense grid as measured here, a simple technique is to choose the closest measurement point.\n",
    "\n",
    "\n",
    "Your task is to implement the nearestPoint function in Binaural_DSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03d80d3a21078030b53587881002db40",
     "grade": false,
     "grade_id": "bb8ebd29-923d-41ae-9c04-eb1c7c982509",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def nearestPoint(self, azi, ele):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return idx_hrir\n",
    "\n",
    "# Add the nearestPoint function to the BinauralDSP class\n",
    "BinauralDSP.nearestPoint = nearestPoint\n",
    "\n",
    "# Get the nearest HRIR index for azimuth 90° (pi/2) and elevation 0°\n",
    "left_hrir_idx = binauralizer.nearestPoint(np.array([np.pi / 2]), np.array([0]))\n",
    "\n",
    "# Plot HRIRs\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Subplot 1: HRIRs\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(binauralizer.hrirs[left_hrir_idx,:,:].squeeze().transpose())\n",
    "plt.title(r'HRIRs for $\\Omega = [90^\\circ, 0^\\circ]$')\n",
    "plt.legend(['Left', 'Right'])\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "\n",
    "# Subplot 2: HRTFs\n",
    "fft_size = 2**13\n",
    "fs = config.fs  # Sampling frequency\n",
    "\n",
    "freqs = np.linspace(0, fs, fft_size)\n",
    "hrtf = np.fft.fft(binauralizer.hrirs[left_hrir_idx,:, :], fft_size, axis=2)\n",
    "hrtf_db = 20 * np.log10(np.abs(hrtf))\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.semilogx(freqs, hrtf_db.squeeze().transpose())\n",
    "plt.title(r'HRTFs for $\\Omega = [90^\\circ, 0^\\circ]$')\n",
    "plt.xlim([20, fs / 2])\n",
    "plt.ylim([-30, 30])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 TASK:  \n",
    "Describe and explain what you see, try to use the terms ITD and ILD!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d7f83745de8398e411fc5d239b83495",
     "grade": false,
     "grade_id": "cell-3d7b3abee63176b3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 TASK: Render a signal with HRTFs\n",
    "a) Implement process for Binaural_DSP\n",
    "\n",
    "b) The band instruments are placed in equal spacing around you:  Write a render loop to apply the HRIRs using binauralizer.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3356d48724c333da20f9e79fbfa3668",
     "grade": false,
     "grade_id": "2d77076b-9d00-4dca-a740-decd7b56c304",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def process(self, in_sig):\n",
    "    assert in_sig.shape[1] == self.numberOfInputs, 'Number of Inputs incorrect.'\n",
    "    \n",
    "    out_sig = np.zeros((self.blockSize, 2))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return out_sig\n",
    "\n",
    "BinauralDSP.process = process\n",
    "\n",
    "# Read audio file\n",
    "inSignals, _ = sfile.read('band_combined_snip.wav')  # [numSamples, numSources]\n",
    "numSources = inSignals.shape[1] if len(inSignals.shape) > 1 else 1\n",
    "\n",
    "# Create source directions\n",
    "sourceDoa = np.column_stack([\n",
    "    np.linspace(0, 2*np.pi - 2*np.pi/numSources, numSources),\n",
    "    np.zeros(numSources)\n",
    "])\n",
    "\n",
    "# Initialize binauralizer\n",
    "binauralizer = BinauralDSP(config, numSources)\n",
    "binauralizer.set_doa(sourceDoa[:, 0], sourceDoa[:, 1])\n",
    "\n",
    "# Block processing\n",
    "blockSize = config.blockSize\n",
    "numBlocks = inSignals.shape[0] // blockSize\n",
    "binauralOut = np.zeros((numBlocks * blockSize, 2))\n",
    "\n",
    "# Implement block processing Hint: Take a look at BlockConvolver_DSP.py\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Plot first 2 seconds\n",
    "plt.figure()\n",
    "time_axis = np.linspace(0, 2, 2 * fs)\n",
    "plt.plot(time_axis, binauralOut[:2*fs, 0], \n",
    "         time_axis, binauralOut[:2*fs, 1])\n",
    "plt.grid(True)\n",
    "plt.legend(['left', 'right'])\n",
    "plt.xlabel('Time in s')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "binauralOut = binauralOut / np.max(np.abs(binauralOut))\n",
    "# Write to file\n",
    "sfile.write('binauralOut.wav', (0.9 * binauralOut).astype(np.float32), fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 TASK: Convex Hull and triangulation of the loudspeaker setup\n",
    "Next, we introduce a new VBAP DSP object to perform directional panning. Before we can actually implement VBAP we need to triangulize the loudspeaker array. Recap from the lecture what a convex hull is and how it is used in VBAP. We provide you a plotting function show_hull() that visualizes the result.\n",
    "\n",
    "Your task is to implement get_conv_hull for VBAP_DSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87b156631a4245d52ed5860838b62b2d",
     "grade": false,
     "grade_id": "fac65f3e-535a-4a3c-8faf-f9b16667a08d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_conv_hull(self):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return hull.simplices\n",
    "  \n",
    "VBAP_DSP.get_conv_hull = get_conv_hull\n",
    "\n",
    "vbap = VBAP_DSP(config.lsPositions)\n",
    "vbap.get_conv_hull()\n",
    "vbap.show_hull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 TASK: Modify loudspeaker setup in config and show hull\n",
    "Experiment with different changes to the loudspeaker positions and see how the convex hull changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff020a1fc18c3b5583801d568370a035",
     "grade": false,
     "grade_id": "a15754ad-692d-47ae-a63e-d86af8b7fcba",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# DUMMY SOLUTION\n",
    "ls_positions_modified = config.lsPositions.copy()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "vbap = VBAP_DSP(ls_positions_modified)\n",
    "vbap.get_conv_hull()\n",
    "vbap.show_hull()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 TASK: Describe and discuss original and alternative loudspeaker setup and its convex hull.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "949291e0cc0940daf02b40dbe0677225",
     "grade": false,
     "grade_id": "cell-28301a0de1793faf",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add virtual sources\n",
    "We revert to original loudspeaker layout, define virtual source positions and show them on top of the loudspeaker layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# Create VBAP object with original loudspeaker layout\n",
    "vbap = VBAP_DSP(config.lsPositions)\n",
    "vbap.get_conv_hull()\n",
    "vbap.show_hull()\n",
    "\n",
    "# Define virtual sources\n",
    "src_azimuth = np.array([0,  np.pi / 8])\n",
    "src_elevation = np.array([0, np.pi / 8])\n",
    "src_radius = np.array([1, 1])\n",
    "\n",
    "# Convert spherical to Cartesian\n",
    "src_position = sph2cart_vec(np.stack((src_azimuth, src_elevation, src_radius), axis=-1))\n",
    "\n",
    "# Plot on top of the loudspeaker layout\n",
    "\n",
    "ax.scatter(src_position[:,0],\n",
    "           src_position[:,1], \n",
    "           src_position[:,2], s=100, color='black', label='Virtual Source', alpha=1, zorder=5)\n",
    "\n",
    "# Add legend and title\n",
    "ax.legend(['Face', 'Loudspeaker', 'Virtual Source'])\n",
    "ax.set_title('Loudspeaker Layout and Virtual Sources')\n",
    "plt.show()\n",
    "# move figure around to see the black dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 TASK: Which loudspeakers should be active?\n",
    "Look at the loudspeaker hull and explain for both virtual sources the expected outcome. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12aebfe5bde0de6fa62f2c9fb1938fe2",
     "grade": false,
     "grade_id": "loudspeaker_activity_task",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 TASK: Implement VBAP \n",
    "Pass the direction of arrival (DOA) angle and calculate the loudspeaker gains for each virtual source. In VBAP_DSP\n",
    "\n",
    "a) Implement invert_bases()\n",
    "\n",
    "b) Implement calculate_gains() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d97be5565a5c023f9b95423eb141a11",
     "grade": false,
     "grade_id": "0b7f7913-8fa4-45df-b018-55a4fb569b7f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def invert_bases(self):\n",
    "    num_faces = self.hull.shape[0]\n",
    "    inv_bases = np.zeros((3, 3, num_faces))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return inv_bases\n",
    "\n",
    "def calculate_gains(self, src_pos):\n",
    "    assert src_pos.shape[1] == 3\n",
    "    num_src = src_pos.shape[0]\n",
    "    gains = np.zeros((num_src, self.num_ls))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return gains\n",
    "\n",
    "# Add Methods to VBA_DSP\n",
    "VBAP_DSP.invert_bases = invert_bases\n",
    "VBAP_DSP.calculate_gains = calculate_gains\n",
    "vbap.inv_bases = vbap.invert_bases()\n",
    "\n",
    "# Set virtual sources\n",
    "vbap.set_sources(src_azimuth, src_elevation)\n",
    "colors = ['r', 'g', 'b', 'm', 'c', 'y'] \n",
    "# Plot the loudspeaker gains\n",
    "plt.figure()\n",
    "for i in range(vbap.ls_gains_new.shape[0]):\n",
    "    color = colors[i % len(colors)]\n",
    "    plt.stem(vbap.ls_gains_new[i], \n",
    "             markerfmt=color + 'o',\n",
    "             linefmt=color + '-',\n",
    "             label=f'Virtual Source {i+1}')\n",
    "\n",
    "plt.xlabel('Loudspeaker')\n",
    "plt.ylabel('Gains')\n",
    "plt.title('Loudspeaker Gains')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 TASK: Test VBAP\n",
    "a) Create 1sec test signals for each virtual source, two pure tones, 20 and 200 Hz, amplitude 0.5 .\n",
    "\n",
    "b) Implement process in VBAP_DSP\n",
    "\n",
    "c) Test rendering with:  lsSignals = vbap.process(inSignals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fa0ef1712824253e45d9960dd44677f",
     "grade": false,
     "grade_id": "89f88e48-f773-4539-a046-e4e84e6b7e5f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# --- DUMMY SOLUTION ---\n",
    "# in_signals = np.zeros((config.fs, 2))\n",
    "# ls_signals = vbap.process(in_signals)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "time = np.arange(ls_signals.shape[0]) / config.fs\n",
    "offset_signals = ls_signals + np.arange(1, ls_signals.shape[1]+1)  # Add offset per channel\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time, offset_signals)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Time in s')\n",
    "plt.ylabel('Signal + LS number offset')\n",
    "plt.title('Loudspeaker Signals')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 TASK: Look at the plots and explain the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d47faea97cef06ba4f7b438bd04683cd",
     "grade": false,
     "grade_id": "cell-29bf2e0e8c86a79d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0e2f6ea6dba8fe9be1e8da67b2d459e",
     "grade": false,
     "grade_id": "73f9bccb-651c-41b2-90a0-db9cfd3d79d4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Read audio ---\n",
    "in_signals, fs = sfile.read('band_combined_snip.wav')  # shape: [samples, channels]\n",
    "\n",
    "# Create scene generator\n",
    "scenes = rotating_band_scene(in_signals, config.blockSize)\n",
    "\n",
    "# --- Initialize Binauralizer ---\n",
    "binauralizer = BinauralDSP(config, config.lsPositions.shape[0])\n",
    "ls_doa = cart2sph_vec(config.lsPositions)\n",
    "binauralizer.set_doa(ls_doa[:, 0], ls_doa[:, 1])\n",
    "\n",
    "assert fs == binauralizer.fs\n",
    "\n",
    "# --- Block Processing ---\n",
    "block_size = config.blockSize\n",
    "num_blocks = len(scenes)\n",
    "binaural_out = np.zeros((num_blocks * block_size, 2))\n",
    "\n",
    "for it_block in range(num_blocks):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# --- Plot waveform (first 2 seconds) ---\n",
    "duration_sec = 2\n",
    "num_samples = int(fs * duration_sec)\n",
    "time_axis = np.linspace(0, duration_sec, num_samples)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(time_axis, binaural_out[:num_samples, 0], label='Left')\n",
    "plt.plot(time_axis, binaural_out[:num_samples, 1], label='Right')\n",
    "plt.xlabel('Time in s')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Binaural Output (First 2 Seconds)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Save output ---\n",
    "#sfile.write('rotatingBand.wav', 0.9 * binaural_out, fs)\n",
    "\n",
    "display(Audio((0.9 * binaural_out.T).astype(np.float32), rate=config.fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License notice\n",
    "This notebook is licensed under CC BY 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark\n",
    "The following watermark might help others to install specific package versions that might be required to run the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.9\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "numpy     : 2.1.3\n",
      "scipy     : 1.15.2\n",
      "pyfar     : 0.7.1\n",
      "sofar     : 1.2.1\n",
      "pooch     : 1.8.2\n",
      "nbgrader  : 0.9.5\n",
      "watermark : 2.5.0\n",
      "matplotlib: 3.10.1\n",
      "ipywidgets: 8.1.5\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.30)\n",
      "OS          : Darwin\n",
      "Release     : 24.5.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pyfar,sofar,pooch,nbgrader,watermark,matplotlib,ipywidgets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
