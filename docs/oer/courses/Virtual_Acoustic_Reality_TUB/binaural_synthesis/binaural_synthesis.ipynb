{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56d9e2314f485b4ae181b0f9193e4092",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Binaural vs. Stereo Audio\n",
    "\n",
    "*Fabian Brinkmann*<br>  \n",
    "*Audio Communication Group, Technische Universität Berlin*<br>  \n",
    "*Contact: fabian.brinkmann@tu-berlin.de*\n",
    "\n",
    "Binaural synthesis aims at creating *virtual sources* anywhere in the 3D space around the listener. In most cases this is done via headphone playback. In contrast, stereo panning creates *phantom sources* on the line between to loudspeakers. In this assignment, you will generate simple binaural and stereo audio examples and compare them against each other.\n",
    "\n",
    "**Duration:** 45-60 Minutes\n",
    "\n",
    "**Requirements:** Basic knowledge of HRTFs, coordinate conventions, and digital signal processing.\n",
    "\n",
    "**References**<br>  \n",
    "[1] F. Brinkmann and C. Pike, “Binauraltechnik,” in Handbuch der Audiotechnik, 2. Auflage., S. Weinzierl, Ed., Berlin, Germany: Springer, 2025. doi: [10.1007/978-3-662-60369-7_27](https://doi.org/10.1007/978-3-662-60369-7_27).\n",
    "\n",
    "**Dependencies**<br>  \n",
    "`pip install pyfar>=0.7 sofar nbgrader ipykernel watermark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a07ae5de206800ac6634211f3e2fb191",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pyfar as pf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import pooch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the assignment, all necessary files need to be downloaded.\n",
    "This is simply done by executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust this path to your needs. Using `None` will download the file to your\n",
    "# system cache.\n",
    "path = None\n",
    "\n",
    "# Leave this as it is: This is the URL from which the data will be downloaded\n",
    "# and a hash for checking if the download worked.\n",
    "url = 'https://github.com/pyfar/files/raw/refs/heads/main/education/VAR_TUB/FABIAN_HRIR_measured_HATO_0.sofa?download='\n",
    "hash = '83ebbcd9a09d17679b95d201c9775438c0bb1199d565c3fc7a25448a905cdc3c'\n",
    "file_hrir = pooch.retrieve(\n",
    "    url, hash, fname='FABIAN_HRIR_measured_HATO_0.sofa', path=path)\n",
    "\n",
    "url = 'https://github.com/pyfar/files/raw/refs/heads/main/education/VAR_TUB/FABIAN_CTF_measured_inverted_smoothed.sofa?download='\n",
    "hash = '68d79bf54ba8e0d7732bf14c525ac20404e751bba26a3e674036c53b71f70bfb'\n",
    "file_ctf_inverse = pooch.retrieve(\n",
    "    url, hash, fname='FABIAN_CTF_measured_inverted_smoothed.sofa', path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fce9ec186f0ad8fecb5a8bce2cd8ea53",
     "grade": false,
     "grade_id": "task_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Load HRTFs and inverted Diffuse Field HRTF\n",
    "\n",
    "Load the HRTF set and its source positions contained in `file_hrir` into pyfar Signal and Coordinates objects, and load the inverse diffuse field HRTF contained in `file_ctf_inverse` into a pyfar Signal object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "848db8342fdcd9c2ca5b7eac5f838cba",
     "grade": false,
     "grade_id": "load_hrtfs_solution",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1d0f8332d2bd8d33bb1440d3aac8ef8",
     "grade": false,
     "grade_id": "task_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Render Auralizations using Binaural Synthesis and Stereo panning\n",
    "\n",
    "In Stereo playback, an audio signal $x(t)$ is panned between the left and the right speaker using the gains $g_\\text{l}$ and $g_\\text{r}$ to produce a *phantom source* that can be perceived anywhere between the two speakers.\n",
    "\n",
    "$l_\\text{l}(t) = g_\\text{l} \\,x(t)$, and\n",
    "\n",
    "$l_\\text{r}(t) = g_\\text{r} \\, x(t)$\n",
    "\n",
    "with the loudspeaker signals $l(t)$. The gains must satisfy $g_\\text{l}^2 + g_\\text{r}^2 = 1$. Equal gains $g_\\text{l} = g_\\text{r}$ evoke a phantom source in the middle of the loudspeakers and $g_\\text{l} = 1$ a phantom source at the position of the left speaker.\n",
    "\n",
    "In contrast, binaural synthesis convolves the audio signal with HRTFs $h(\\varphi,\\vartheta, t)$ and delivers the resulting ear signals $e(t)$ via headphones\n",
    "\n",
    "$e_\\text{l,r}(t) = x(t) \\ast h_\\text{l,r}(\\varphi,\\vartheta, t) \\ast c_\\text{l,r}(t)$\n",
    "\n",
    "with azimuth $\\varphi$ and elevation $\\vartheta$ and a compensation filter $c(t)$ that linearizes the transfer function of the headphone to achieve a natural sound color. In this assignment, you will use the inverse diffuse field HRTFs as $c(t)$, i.e., the HRTF that is first averaged across all source positions and then inverted.\n",
    "\n",
    "Go ahead and render binaural and stereo signals. You will plot the binaural transfer functions and listen to the resulting auralizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d2877b61d5d4175a6d4a2d72a69dc2c",
     "grade": false,
     "grade_id": "render_auralizations_solution",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Source position - select one of the following:\n",
    "# front, back, left, right, up, down\n",
    "position = 'left'\n",
    "\n",
    "# flag for applying diffuse field compensation\n",
    "diffuse_field_compensation = True\n",
    "\n",
    "# load or generate audio content\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# set the source positions for binaural rendering and the channel gains for stereo auralization\n",
    "if position == 'front':\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "elif position == 'back':\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "elif position == 'left':\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "elif position == 'right':\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "elif position == 'up':\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "elif position == 'down':\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "else:\n",
    "    raise ValueError(f'Invalid {position = }')\n",
    "\n",
    "# render HRTF based auralization\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# render stereo based auralization\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# force equal energy in both auralizations as a simple loudness normalization\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Normalize the auralizations to the highest occuring amplitude (use the same normalization for both auralizations)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# render the audio using the iPython `Audio`` widget\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# plot the left and right ear HRIR and HRTF\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License notice\n",
    "\n",
    "This notebook is licensed under CC BY 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark\n",
    "\n",
    "The following watermark might help others to install specific package versions that might be required to run the notebook. Please give at least the versions of Python, IPython, numpy , and scipy, major third party packagers (e.g., pytorch), and all used pyfar packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.13.4\n",
      "IPython version      : 9.1.0\n",
      "\n",
      "numpy    : 2.3.0\n",
      "scipy    : 1.15.3\n",
      "pyfar    : 0.7.3\n",
      "sofar    : 1.2.2\n",
      "nbgrader : 0.9.5\n",
      "watermark: 2.5.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pyfar,sofar,nbgrader,watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfar_oer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
