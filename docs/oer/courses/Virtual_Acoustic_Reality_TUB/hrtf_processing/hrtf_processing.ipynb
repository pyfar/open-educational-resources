{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRTFs: Identification and Normalization\n",
    "*Fabian Brinkmann*<br>  \n",
    "*Audio Communication Group, Technische Universität Berlin*<br>  \n",
    "*Contact: fabian.brinkmann@tu-berlin.de*\n",
    "\n",
    "The task of this notebook is (i) to perform a system identification, that is, to estimate HRTFs based on raw data from sweep-based acoustic measurements in a first step, and (ii) to normalize the HRTFs in a second step, that is, to apply a standardized post-processing with the goal to minimize differences between HRTFs of the same subject that were measured at different facilities.\n",
    "\n",
    "**Duration:** 180-360 Minutes\n",
    "\n",
    "**Requirements:** Basic knowledge of HRTFs and coordinate conventions. Good knowledge of digital signal processing and pyfar.\n",
    "\n",
    "**References**<br>  \n",
    "[1] H. Møller, “Fundamentals of binaural technology,” Appl. Acoust., vol. 36, pp. 171–218, 1992, doi: [10.1016/0003-682x(92)90046-u](https://doi.org/10.1016/0003-682x(92)90046-u).  \n",
    "[2] H. Bahu et al., “Towards improved consistency between databases of head-related transfer functions,” J. Audio Eng. Soc., 2025.  \n",
    "[3] F. Brinkmann et al., “A High Resolution and Full-Spherical Head-Related Transfer Function Database for Different Head-Above-Torso Orientations,” J. Audio Eng. Soc., vol. 65, no. 10, pp. 841–848, Oct. 2017, doi: [10.17743/jaes.2017.0033](https://dio.org/10.17743/jaes.2017.0033).  \n",
    "[4] B. Xie, “On the low frequency characteristics of head-related transfer function,” Chinese J. Acoust., vol. 28, no. 2, pp. 1–13, 2009.  \n",
    "[5] B. Bernschütz, “A spherical far field HRIR/HRTF compilation of the Neumann KU 100,” in AIA-DAGA 2013, International Conference on Acoustics, Merano, Italy, Mar. 2013, pp. 592–595.  \n",
    "[6] R. O. Duda and W. L. Martens, “Range dependence of the response of a spherical head model,” J. Acoust. Soc. Am., vol. 104, no. 5, pp. 3048–3058, 1998.  \n",
    "\n",
    "**Dependencies**<br>  \n",
    "`pip install pyfar>=0.7 pooch nbgrader ipykernel watermark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfar as pf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import pooch\n",
    "import os\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load example data\n",
    "\n",
    "The following downloads the data for this task: recorded sine sweeps for five source positions from the FABIAN HRTF database [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust this path to your needs. Using `None` will download the file to your\n",
    "# system cash.\n",
    "path = None\n",
    "\n",
    "# Leave this as it is: This is the URL from which the data will be downloaded\n",
    "# and a hash for checking if the download worked.\n",
    "url = 'https://github.com/pyfar/files/raw/refs/heads/main/education/VAR_TUB/hrtf_post_processing_and_normalization.far?download='\n",
    "hash = '1f4e7ad698ce65c1e359d914918fa9f4f81ca611eb9812243b55798fb2462732'\n",
    "\n",
    "file = pooch.retrieve(\n",
    "    url, hash, fname='hrtf_post_processing_and_normalization.far', path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads the data as pyfar Signal and Coordinate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "baef1b90019905b020a2b758df452ecf",
     "grade": false,
     "grade_id": "cell-140a2f4c7a92600f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we download and import Python code for a spherical head model that will be used in the normalization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this as it is: This is the URL from which the data will be downloaded\n",
    "url = 'https://github.com/pyfar/open-educational-resources/tree/main/docs/oer/courses/Virtual_Acoustic_Reality_TUB/hrtf_processing/spherical_head.py?raw=true'\n",
    "hash = '7e30984c122dbc6df2c76ee073c8c6bc4c3d750ddb10186cd547ab5c18ee23c6'\n",
    "\n",
    "# Download to the directory of this notebook for importing\n",
    "_ = pooch.retrieve(\n",
    "    url, hash, fname='spherical_head.py', path=os.getcwd())\n",
    "\n",
    "from spherical_head import spherical_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get familiar with the data\n",
    "\n",
    "It is always good to get to know the data you are working with. Start by plotting the scene geometry defined by the positions loaded as pyfar coordinate objects above. You should know the following:\n",
    "\n",
    "- For how many and which source position are the data available?\n",
    "- Where were the microphones located during the HRIR and reference measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7682fc4fb5e837c457db6298c1fe9219",
     "grade": false,
     "grade_id": "cell-ad032f75ec9a2713",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a recorded sweeps and use [pyfar plot shortcuts](https://pyfar.readthedocs.io/en/stable/modules/pyfar.plot.html#pyfar.plot.shortcuts) to inspect the sweep in the time and frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "071098a1ee71b6b73b3462c8e0ec41b1",
     "grade": false,
     "grade_id": "cell-17e6f0aa75ca95e0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play back the same sweep via headphones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "006d52a6ea59837d58dd85a75a0f41e1",
     "grade": false,
     "grade_id": "cell-789999427f9eca43",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1a37e8085d54ea770603f44dc2e8947",
     "grade": false,
     "grade_id": "task_2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Deconvolution\n",
    "\n",
    "The first step is to obtain the raw HRTF by means of deconvolution, i.e.,\n",
    "\n",
    "$$H = \\frac{P_\\text{ear}}{P_\\text{reference}} \\, \\mathrm{e}^{-\\mathrm{j}\\omega\\tau} = P_\\text{ear} \\, \\frac{1}{P_\\text{reference}} \\, \\mathrm{e}^{-\\mathrm{j}\\omega\\tau}$$\n",
    "\n",
    "Where $H$ is the HRTF (complex spectrum) and $\\tau$ a delay to force causality. You will soon see, why this is required.\n",
    "\n",
    "**NOTE:** From now on, you should always visualize the processing steps for all data to inspecting if things went according to plan.\n",
    "\n",
    "### a) Invert reference\n",
    "\n",
    "Note that regularization is often used to compute the inverse $1/P_\\text{reference}$ to avoid excessive gains when inverting band-limited signals. This is done to not boost out-of-band noise. You can realize this and most other processing steps can be done with the `pyfar.dsp` module.\n",
    "\n",
    "The regularization will later act on the HRIRs as a band pass. Bahu et al. [2, Sec. 1.1] suggest to low-pass at 18 kHz to normalize measurements across different datasets. If measurements are valid beyond this range, it does not harm to increase the low-pass frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec652fa21d8b1739a0f295d1505ce1e2",
     "grade": false,
     "grade_id": "cell-a402cc2a6a8a8829",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sweep inversion\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Deconvolve\n",
    "\n",
    "Next, perform a frequency domain multiplication of the sweeps recorded at the ear channels with the inverse computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbebabb100c12bd1aa34f9075fdf0eb0",
     "grade": false,
     "grade_id": "cell-620ca4fcf26f71d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you carefully inspect the result? You might have noticed that some of the time domain signals have significant energy at the end of the impulse response. This comes from the deconvolution that can be written as\n",
    "\n",
    "$$\\frac{P_\\text{ear}}{P_\\text{reference}} = \\frac{|P_\\text{ear}|}{|P_\\text{reference}|} \\mathrm{e}^{\\mathrm{j}\\omega(\\tau_\\text{ear} - \\tau_\\text{reference})}\\,,$$\n",
    "\n",
    "which shows that the group delay of the reference $\\tau_\\text{reference}$ is subtracted from the group delay of the ear signals $\\tau_\\text{reference}$. Hence, the HRIRs become acausal if the source position is closer to the ear than the reference position.\n",
    "\n",
    "### c) Force causality\n",
    "\n",
    "Correct this with a cyclic time shift. For now, make sure the shift is large enough. You will refine the temporal alignment in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7aaf3dab2dd4cecb6dac7244f38b6938",
     "grade": false,
     "grade_id": "cell-9a1180595524ed46",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Temporal alignment\n",
    "\n",
    "As suggested by Bahu et al. [2, Sec. 1.2] you should now align the HRIRs by\n",
    "\n",
    "- Estimating the onsets of the HRIR for the frontal source position. It is suggested to use leading-edge detection with a threshold of 20 dB. This can be done with `pyfar.dsp.find_impulse_response_start`.\n",
    "- Shift all HRIRs so to make sure the frontal HRIR starts after 1 ms. Use the smaller onset, if they differ across the left and right ear.\n",
    "\n",
    "Start by detecting the onset time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ede3b3e5fe941e92eef8bfc7dc4417b7",
     "grade": false,
     "grade_id": "cell-aa0a44326acc3b95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now shift HRIRs to make sure that the frontal HRIR starts at 1 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa406f8d241b1eb96d59cdd71192ccf7",
     "grade": false,
     "grade_id": "cell-04bdd6d9ce5a95da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you focused on inspecting the frontal HRIR only it is now time to check how all aligned HRIRs look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ddd5c568fe2614c1cf572e52fbf4c4d",
     "grade": false,
     "grade_id": "cell-5085b6c2913a2853",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Windowing\n",
    "\n",
    "Acoustic measurements usually contain reflections, even if they were done in an anechoic chamber. In this case reflections may come from the measurement equipment itself (other loudspeakers, supporting construction, etc.) or from the room (door, floor, etc.).\n",
    "\n",
    "Reflections show up in the impulse response as peaks that follow the direct sound. In the spectrum they cause a ripple (comb-filter) effect.\n",
    "\n",
    "Reflections are commonly discarded by applying a time window to IRs and Bahu et al. [2, Sec. 1.3] suggest an asymmetric Hann window with a length of 5.8 ms, a fade in of 0.25 ms and a fade out of 1 ms. The fade in should start 0.25 ms before the earliest onset detected in the HRIR dataset.\n",
    "\n",
    "Note: The length and fade-in are recommendations that should work in many cases. In some cases a longer window might be possible, or a shorter window might be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "956357a50fb97fb2f2c6507ad09787fa",
     "grade": false,
     "grade_id": "cell-7c8e04609582711f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# find the earliest onset in the HRIR dataset\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# window the HRIRs\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# plot windowed HRIRs and window\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# plot HRTFs before and after windowing\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you inspected the HRIRs, you might have noticed that\n",
    "\n",
    "- the HRIRs become much smoother after the reflections are windowed away, especially for HRIRs in the head shadow zone\n",
    "- the frequency resolution changed, if you truncated the HRIRs after 5.8 ms\n",
    "- the low frequency response changed, which can best be seen on a linear frequency axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Low-frequency extrapolation\n",
    "\n",
    "Due to the limited frequency range of loudspeakers commonly used to measure HRTFs, the HRTF is usually invalid at low-frequencies and must be estimated by means of extrapolation.\n",
    "\n",
    "At low frequencies, the HRTF magnitude is close to 0 dB. It is not exactly 0 dB due to the difference between the distances from the source positions to the ear and to the reference position at the center of the head. Bahu et al. [2, Sec. 1.5] suggest to interpolate between the magnitude of a spherical head model at 0 Hz and the HRTF magnitude at a cut-off frequency $f_c$, above which the measured HRTFs are valid.\n",
    "\n",
    "More extrapolation approaches have been suggested from which you could chose as well\n",
    "\n",
    "- Xie [4] suggest linear extrapolation of the magnitude and unwrapped phase response to 0.\n",
    "- Bernschütz [5] suggests a Linkwitz-Riley crossover network with a time-aligned low-pass.\n",
    "- Numerically simulated HRTFs [3] or a spherical head model [6] can be used to replace the HRTF at invalid frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bb71581b69e2eaaf303510cbc18cf08",
     "grade": false,
     "grade_id": "cell-fab05fd4d3158d7c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute spherical head transfer functions using `spherical_head()`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now carefully inspect the data to decide above which frequency it is still valid. A possibility to determine this is to see above which frequency the aligned HRTFs have approximately the same magnitude as the windowed HRTFs. Note that this frequency limit can depend on the source position and the time window applied in a previous step.\n",
    "\n",
    "Chose the frequency above which the HRTFs are left unchanged and extrapolate below this frequency.\n",
    "\n",
    "Note: The magnitude of a spherical head HRTF with a radius of 8.75 cm is approximately constant below 200 Hz. You could apply the target values from this frequency downwards. Or find a frequency for which extrapolation best matches HRTFs before windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "198836cd6de43b157b05926f08520a94",
     "grade": false,
     "grade_id": "cell-d7b9c11c0b91d6a2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Far-field extrapolation\n",
    "\n",
    "The previous sections showed that the low-frequency HRTF magnitude depends on the distance at which the HRTFs were measured, which might not always be desired.\n",
    "\n",
    "To correct this, Bahu et al. [2, Sec. 1.6] suggest to compute distance distance variation functions (DVFs) using Spherical Head Transfer Functions (SHTF)\n",
    "\n",
    "$$\\mathrm{DVF}(r_\\text{m}, r_\\text{ref}, \\Omega) = \\frac{\\mathrm{SHTF}(r_\\text{ref}, \\Omega)}{\\mathrm{SHTF}(r_\\text{m}, \\Omega)}$$\n",
    "\n",
    "where $r_\\text{m}$ is the distance at which the HRTFs were measured, $r_\\text{ref}=100$ m a distance in the far-field, and $\\Omega$ the source position given by azimuth and elevation.\n",
    "\n",
    "Compute the DVS wuth the `spherical_head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc43c3092455da769efd1fc2e257201d",
     "grade": false,
     "grade_id": "cell-8185581698b26aba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the far-field extrapolation by applying the DVSs to the HRTFs\n",
    "\n",
    "$$\\mathrm{HRTF}(r_\\text{ref}, \\Omega) = \\mathrm{HRTF}(r_\\text{m}, \\Omega) * \\mathrm{DVF}(r_\\text{m}, r_\\text{ref}, \\Omega)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8be2db5537c456d5a8524d262079c79e",
     "grade": false,
     "grade_id": "cell-20c3cb5b5e310b98",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec4d1b72c1a31e7dd519f2f5e318771b",
     "grade": false,
     "grade_id": "task_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 8. Truncate to final length\n",
    "\n",
    "HRIRs should be as short as possible, usually they can be shortened to 256 or even 128 samples after proper low-frequency extrapolation.\n",
    "\n",
    "You can optionally truncate the HRIR and compare it to the full-length version. Although you windowed the HRIRs before, the low-frequency extrapolation most likely changed the time signal. It might hence be useful to apply a second time window including fade-in and fade-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7162e3a392afa2f35571325b4fd2f545",
     "grade": false,
     "grade_id": "cell-848293361df6d621",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# window to final length\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# compare against full length (pad zeros to increase FFT resolution)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Diffuse field equalization\n",
    "\n",
    "HRTFs are diffuse-field equalized by a spectral division of each HRTF by the HRTF averaged across source positions, also called Diffuse-Field HRTF or Common Transfer Function (CTF). After equalization the HRTFs are often referred to as Directional Transfer Functions (DTFs).\n",
    "\n",
    "There are multiple ways to average across source positions, of which the RMS is one possibility\n",
    "\n",
    "$$\\mathrm{CTF}_{l,r}(f) = \\sqrt{\\frac{1}{Q} \\sum_q^{Q-1} |w_q \\, \\mathrm{HRTF}_q(f)|^2}$$\n",
    "\n",
    "with indices $l$ and $r$ denoting the left and right ear, $w_q$ optional weights for averaging, the  frequency $f$, and the number of sources $Q$. The diffuse-field equalization is often done separately for the left and right ear. This removes natural differences between the left and right ear, but could also mitigate measurement errors, e.g., an incorrect microphone placement. If this is not desired the above should also average across ears.\n",
    "\n",
    "Note:\n",
    "\n",
    "- dividing by the CTF equals multiplying by its inverse. It might be best to again use regulated inversion\n",
    "- the CTF is zero phase by definition and making it minimum-phase is suggested by Bahu et al. [2, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c8ef5132bdf9bd18f7cb3282e03c16b",
     "grade": false,
     "grade_id": "cell-98a8b00dde38bd17",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute the CTF\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# plot CTF and CTF inverse\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the inverse CTF in a final processing step to obtain the directional transfer functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b59347e0ad7aa8b046711801733ffa8",
     "grade": false,
     "grade_id": "cell-f669bd37d1a9db51",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute CTFs\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# compare HRTFs and DTFs\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "Note that no measurement is like the other. The parameters that worked here, must not necessarily work for other data. Always check all your processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License notice\n",
    "\n",
    "This notebook is licensed under CC BY 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark\n",
    "\n",
    "The following watermark might help others to install specific package versions that might be required to run the notebook. Please give at least the versions of Python, IPython, numpy , and scipy, major third party packagers (e.g., pytorch), and all used pyfar packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.13.4\n",
      "IPython version      : 9.1.0\n",
      "\n",
      "numpy    : 2.3.3\n",
      "scipy    : 1.15.3\n",
      "pyfar    : 0.7.3\n",
      "sofar    : 1.2.2\n",
      "nbgrader : 0.9.5\n",
      "watermark: 2.5.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pyfar,sofar,nbgrader,watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfar_oer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
